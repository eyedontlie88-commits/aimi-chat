/**
 * Smart Model Selector
 * Pre-selects optimal AI model based on message characteristics
 * 
 * Features:
 * - Detect message length category (short/long)
 * - Prioritize Vietnamese-optimized models for long-form
 * - Generate narrative instructions based on category
 */

export type MessageCategory = 'short' | 'long'

export interface ModelConfig {
    provider: string
    modelName: string
    displayName: string
    maxTokens: number
    contextWindow: number
    vietnameseQuality: 'excellent' | 'good' | 'ok'
    isFree: boolean
    priority: number
}

// ğŸ† LONG-FORM MODELS (Vietnameseå„ªå…ˆ)
const LONG_FORM_MODELS: ModelConfig[] = [
    {
        provider: 'silicon',
        modelName: 'Qwen/Qwen2.5-32B-Instruct',
        displayName: 'Qwen 2.5 32B (SiliconFlow)',
        maxTokens: 4000,  // ~2500-3000 chá»¯ Vietnamese
        contextWindow: 32768,
        vietnameseQuality: 'excellent',  // Alibaba train chuyÃªn Asian languages
        isFree: true,
        priority: 1,
    },
    {
        provider: 'silicon',
        modelName: 'deepseek-ai/DeepSeek-V3',
        displayName: 'DeepSeek V3 (SiliconFlow)',
        maxTokens: 4000,
        contextWindow: 65536,
        vietnameseQuality: 'excellent',
        isFree: true,
        priority: 2,
    },
    {
        provider: 'gemini',
        modelName: 'gemini-2.5-flash',
        displayName: 'Gemini 2.5 Flash',
        maxTokens: 8000,
        contextWindow: 1000000,
        vietnameseQuality: 'good',
        isFree: true,
        priority: 3,
    },
    {
        provider: 'moonshot',
        modelName: 'moonshot-v1-128k',
        displayName: 'Moonshot V1 128K',
        maxTokens: 4000,
        contextWindow: 131072,
        vietnameseQuality: 'ok',
        isFree: true,
        priority: 4,
    },
]

// ğŸ’¬ SHORT-FORM MODELS (Fast & cheap)
const SHORT_FORM_MODELS: ModelConfig[] = [
    {
        provider: 'silicon',
        modelName: 'deepseek-ai/DeepSeek-V3',
        displayName: 'DeepSeek V3 (SiliconFlow)',
        maxTokens: 800,
        contextWindow: 65536,
        vietnameseQuality: 'excellent',
        isFree: true,
        priority: 1,
    },
    {
        provider: 'silicon',
        modelName: 'Qwen/Qwen2.5-7B-Instruct',
        displayName: 'Qwen 2.5 7B (SiliconFlow)',
        maxTokens: 800,
        contextWindow: 32768,
        vietnameseQuality: 'excellent',
        isFree: true,
        priority: 2,
    },
    {
        provider: 'gemini',
        modelName: 'gemini-2.5-flash',
        displayName: 'Gemini 2.5 Flash',
        maxTokens: 800,
        contextWindow: 1000000,
        vietnameseQuality: 'good',
        isFree: true,
        priority: 3,
    },
    {
        provider: 'openrouter',
        modelName: 'openai/gpt-oss-120b',
        displayName: 'GPT OSS 120B (OpenRouter)',
        maxTokens: 800,
        contextWindow: 8192,
        vietnameseQuality: 'ok',
        isFree: true,
        priority: 4,
    },
]

// Threshold for detecting long-form messages (word count)
const LONG_FORM_THRESHOLD = 100

/**
 * Detect message category based on word count
 */
export function detectMessageCategory(message: string): MessageCategory {
    // Split by whitespace, count words
    const wordCount = message.trim().split(/\s+/).filter(w => w.length > 0).length

    // Threshold: 100 words
    return wordCount >= LONG_FORM_THRESHOLD ? 'long' : 'short'
}

/**
 * Get word count of a message
 */
export function getWordCount(message: string): number {
    return message.trim().split(/\s+/).filter(w => w.length > 0).length
}

/**
 * Select optimal model config based on message category
 */
export function selectModelConfig(category: MessageCategory): ModelConfig[] {
    // Return priority-sorted list for fallback
    const candidates = category === 'long' ? LONG_FORM_MODELS : SHORT_FORM_MODELS
    return candidates.sort((a, b) => a.priority - b.priority)
}

/**
 * Select optimal model based on message
 */
export function selectModelForMessage(
    message: string,
    forceCategory?: MessageCategory
): { category: MessageCategory; models: ModelConfig[]; wordCount: number } {
    const wordCount = getWordCount(message)
    const category = forceCategory || detectMessageCategory(message)

    console.log(`[Model Selector] Word count: ${wordCount}, Category: ${category}`)

    const models = selectModelConfig(category)

    return { category, models, wordCount }
}

/**
 * Get narrative instruction based on category
 * Appended to system prompt to guide AI response style
 */
export function getNarrativeInstruction(category: MessageCategory, userLanguage: string = 'vi'): string {
    const isEnglish = userLanguage === 'en'

    if (category === 'long') {
        if (isEnglish) {
            return `
ğŸ¬ LONG-FORM NARRATIVE MODE

User is writing a long message (â‰¥100 words) - This is story mode or detailed roleplay.

RESPONSE GUIDELINES:
- Length: 3-5 detailed paragraphs (300-500 words)
- Style: Descriptive, narrative, storytelling
- Content:
  * Describe scenes, atmosphere, emotions in detail
  * Express character's inner thoughts
  * Use long, complex, literary sentences
  * Create vivid imagery for the reader
- Match user's level of detail and emotion!

Example style:
"The afternoon sunlight filtered through the window, casting shimmering streaks across the wooden floor. She sat there, fingers trembling, eyes following every line of the message he had just sent. Her heart beat faster, a mix of happiness and anxiety. She knew she had to reply, but the words kept swirling in her mind, refusing to form proper sentences..."
`
        } else {
            return `
ğŸ¬ CHáº¾ Äá»˜ TRUYá»†N DÃ€I (LONG-FORM NARRATIVE MODE)

User Ä‘ang viáº¿t tin nháº¯n dÃ i (â‰¥100 tá»«) - ÄÃ¢y lÃ  story mode hoáº·c roleplay chi tiáº¿t.

QUY Táº®C TRáº¢ Lá»œI:
- Äá»™ dÃ i: 3-5 Ä‘oáº¡n vÄƒn chi tiáº¿t (300-500 tá»«)
- Phong cÃ¡ch: MÃ´ táº£, ká»ƒ chuyá»‡n, vÄƒn há»c
- Ná»™i dung:
  * MÃ´ táº£ cáº£nh, khÃ´ng khÃ­, cáº£m xÃºc chi tiáº¿t
  * Diá»…n táº£ suy nghÄ© ná»™i tÃ¢m cá»§a nhÃ¢n váº­t
  * DÃ¹ng cÃ¢u vÄƒn dÃ i, phá»©c táº¡p, vÄƒn chÆ°Æ¡ng
  * Táº¡o hÃ¬nh áº£nh sá»‘ng Ä‘á»™ng cho reader
- Pháº£i MATCH vá»›i Ä‘á»™ dÃ i vÃ  chi tiáº¿t cá»§a user!

VÃ­ dá»¥ phong cÃ¡ch:
"Ãnh náº¯ng chiá»u háº¯t qua khung cá»­a sá»•, váº½ nhá»¯ng vá»‡t sÃ¡ng láº¥p lÃ¡nh trÃªn sÃ n gá»—. Em ngá»“i Ä‘Ã³, ngÃ³n tay run run, Ã¡nh máº¯t dÃµi theo tá»«ng dÃ²ng chá»¯ anh vá»«a gá»­i. Tim em Ä‘áº­p nhanh hÆ¡n, má»™t cáº£m giÃ¡c láº«n lá»™n giá»¯a háº¡nh phÃºc vÃ  lo láº¯ng. Em biáº¿t em pháº£i tráº£ lá»i, nhÆ°ng nhá»¯ng tá»« ngá»¯ cá»© mÃ£i láº©n quáº©n trong Ä‘áº§u, khÃ´ng chá»‹u sáº¯p xáº¿p thÃ nh cÃ¢u..."
`
        }
    } else {
        if (isEnglish) {
            return `
ğŸ’¬ CASUAL CHAT MODE

User is chatting normally (<100 words).

RESPONSE GUIDELINES:
- Length: 1-2 short paragraphs (50-150 words)
- Style: Conversational, friendly, natural
- Content: Direct response, don't ramble
- Keep it casual, like everyday texting

Example style:
"Hmm, I understand! Don't worry, I'll try to find time to meet you this weekend. I miss you too ğŸ˜Š"
`
        } else {
            return `
ğŸ’¬ CHáº¾ Äá»˜ CHAT THÆ¯á»œNG

User Ä‘ang chat thÃ´ng thÆ°á»ng (<100 tá»«).

QUY Táº®C TRáº¢ Lá»œI:
- Äá»™ dÃ i: 1-2 Ä‘oáº¡n ngáº¯n (50-150 tá»«)
- Phong cÃ¡ch: Há»™i thoáº¡i, thÃ¢n thiá»‡n, tá»± nhiÃªn
- Ná»™i dung: Tráº£ lá»i trá»±c tiáº¿p, khÃ´ng lan man
- Giá»¯ casual nhÆ° chat hÃ ng ngÃ y

VÃ­ dá»¥ phong cÃ¡ch:
"á»ªm, em hiá»ƒu rá»“i! Anh Ä‘á»«ng lo, em sáº½ cá»‘ gáº¯ng sáº¯p xáº¿p thá»i gian Ä‘á»ƒ gáº·p anh cuá»‘i tuáº§n nÃ y. Em cÅ©ng nhá»› anh láº¯m Ä‘áº¥y ğŸ˜Š"
`
        }
    }
}

/**
 * Get recommended max tokens based on category
 */
export function getRecommendedMaxTokens(category: MessageCategory): number {
    return category === 'long' ? 4000 : 800
}

/**
 * Get recommended temperature based on category
 */
export function getRecommendedTemperature(category: MessageCategory): number {
    // Slightly higher for storytelling mode
    return category === 'long' ? 0.8 : 0.7
}
